{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b31d2a-2157-4c15-8ce2-a865241e0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22529/337515062.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from causallearn.utils.cit import CIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb635a55-b3f5-4749-a881-8f617f5e6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../submodules/pyCausalFS/pyCausalFS')\n",
    "sys.path.append('../submodules/pyCausalFS/pyCausalFS/CBD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a72d86-4fa3-475d-8ca3-76b77bf6e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from MBs.semi_HITON.semi_HITON_PC import semi_HITON_PC\n",
    "#from MBs.semi_HITON.semi_HITON_MB import semi_HITON_MB\n",
    "from MBs.common.subsets import subsets\n",
    "from MBs.common.condition_independence_test import cond_indep_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834a62d7-46eb-4c94-943c-795edacf1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tie_small_data = np.load('../data/tie_small.npy')\n",
    "with open('../data/tie_small_names.json', 'r') as jf:\n",
    "    tie_small_names = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55923045-4d6d-48d7-b000-feec378a5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_parent(cit, node, candidates, existing_parents, threshold):\n",
    "    \"\"\"\n",
    "    Find the best parent for a node among the candidate parents\n",
    "    based on the G-squared (chi-squared) test with a threshold.\n",
    "    \"\"\"\n",
    "    best_parents = []\n",
    "    for candidate in candidates:\n",
    "        if candidate != node and candidate not in existing_parents:\n",
    "            p_value = cit(node, candidate, existing_parents)\n",
    "            if p_value < threshold:\n",
    "                best_parents.append(candidate)\n",
    "    return best_parents\n",
    "\n",
    "def semi_hiton_pc(data, labels, target, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Semi-Interleaved HITON-PC algorithm for learning the Markov boundary\n",
    "    of a target variable from discrete data using G-squared test for independence.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialization\n",
    "    markov_boundary = set()\n",
    "    visited = set()\n",
    "    cit = CIT(data, \"gsq\")\n",
    "    indices = [i for i in range(len(labels))]\n",
    "    target_idx = labels.index(target)\n",
    "    queue = [target_idx]\n",
    "\n",
    "    # Step 2: Forward phase\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        visited.add(node)\n",
    "        candidates = set(indices) - {node} - visited\n",
    "        best_parents = find_best_parent(cit, node, candidates, markov_boundary, threshold)\n",
    "        markov_boundary.update(best_parents)\n",
    "        queue.extend(best_parents)\n",
    "\n",
    "    print(markov_boundary)\n",
    "    # Step 3: Backward phase\n",
    "    while markov_boundary:\n",
    "        node = markov_boundary.pop()\n",
    "        candidates = set(indices) - {node} - markov_boundary\n",
    "        best_parents = find_best_parent(cit, node, candidates, markov_boundary, threshold)\n",
    "        markov_boundary.update(best_parents)\n",
    "        print(markov_boundary)\n",
    "\n",
    "    # Step 4: Remap to labels\n",
    "    return markov_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eebb0666-5f88-4934-81ea-58f928f6f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dependencies(data, target, alpha, cit):\n",
    "    dependencies = []\n",
    "    for x in range(data.shape[1]):\n",
    "        if x != target:\n",
    "            #pval, dep = cond_indep_test(data, target, x, [])\n",
    "            #print(pval, dep)\n",
    "            pval = cit(target, x, None)\n",
    "            if pval <= alpha:\n",
    "                dependencies.append((x, pval))\n",
    "    return sorted(dependencies, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "def find_parents(data, target, alpha, dependencies, cit):\n",
    "    parents = []\n",
    "    for x, dep in dependencies:\n",
    "        parents.append(x)\n",
    "        conditions = [i for i in parents if i != x]\n",
    "        if len(conditions) >= 3:\n",
    "            length = 3\n",
    "        else:\n",
    "            length = len(conditions)\n",
    "        for j in range(length + 1):\n",
    "            for s in subsets(conditions, j):\n",
    "                #pval, _ = cond_indep_test(data, x, target, s)\n",
    "                pval = cit(x, target, s)\n",
    "                if pval > alpha:\n",
    "                    parents.remove(x)\n",
    "                    break\n",
    "    return parents\n",
    "\n",
    "def semi_HITON_PC(data, target, alpha, cit, is_discrete=True):\n",
    "    dependencies = find_dependencies(data, target, alpha, cit)\n",
    "    parents = find_parents(data, target, alpha, dependencies, cit)\n",
    "    return parents, [], len(dependencies) + len(parents)\n",
    "\n",
    "def semi_HITON_MB(data, target, alpha, is_discrete=True):\n",
    "    cit = CIT(data, \"gsq\")\n",
    "    TPC, _, ci_number = semi_HITON_PC(data, target, alpha, cit, is_discrete)\n",
    "    MB = TPC.copy()\n",
    "    for x in TPC:\n",
    "        x_parents, _, ci_number2 = semi_HITON_PC(data, x, alpha, cit, is_discrete)\n",
    "        ci_number += ci_number2\n",
    "        for y in x_parents:\n",
    "            if y != target and y not in TPC:\n",
    "                condition_set = set()\n",
    "                for z in MB:\n",
    "                    condition_set.add(z)\n",
    "                condition_set.update([x])\n",
    "                #pval, _ = cond_indep_test(data, target, y, list(condition_set), is_discrete)\n",
    "                pval = cit(target, y, list(condition_set))\n",
    "                if pval <= alpha:\n",
    "                    MB.append(y)\n",
    "                    break\n",
    "    return list(set(MB)), ci_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "613b8437-3f4a-4f8c-a527-531cf6f0058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def contains_G_star(G_star, G):\n",
    "    for g_star in G_star:\n",
    "        if len(g_star) == 0:\n",
    "            continue\n",
    "        if g_star.issubset(G):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_embedded_dataset(data, G):\n",
    "    idx_map = list(range(data.shape[1]))\n",
    "    for i in G:\n",
    "        idx_map[i] = -1\n",
    "        for j in range(i + 1, data.shape[1]):\n",
    "            idx_map[j] -= 1\n",
    "    map = {}\n",
    "    for i, j in enumerate(idx_map):\n",
    "        map[i] = j\n",
    "    imap = {j: i for i, j in map.items()}\n",
    "    # Delete columns in G\n",
    "    embed_data = np.delete(data, list(G), 1)\n",
    "    return embed_data, map, imap\n",
    "\n",
    "def check_independence_M_new(data, target, alpha, cit, M_new, M, G):\n",
    "    W = set.intersection(*[M, M_new])\n",
    "    S1 = M - M_new\n",
    "    S2 = M_new - M\n",
    "    for Y in S1:\n",
    "        if cit(target, Y, list(S2)) > alpha:\n",
    "            return False\n",
    "    for Y in S2:\n",
    "        if cit(target, Y, list(S1)) > alpha:\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "def tie_star(data, target, alpha, is_discrete=True):\n",
    "    # Find the Markov Boundary of the entire dataset\n",
    "    V = set(range(data.shape[1]))\n",
    "    M, _ = semi_HITON_MB(data, target, alpha, is_discrete)\n",
    "    print('M', M)\n",
    "    M_queue = [set(M)]\n",
    "    G_queue = [[]]\n",
    "    G_star = [set()]\n",
    "    cit = CIT(data, \"gsq\")\n",
    "    \n",
    "    # Now iterate to find other Markov boundaries from embedded distributions\n",
    "    for i in range(1, len(V) - 1):\n",
    "        for _G in itertools.combinations(V - {target}, i):\n",
    "            print('_G', _G)\n",
    "            if contains_G_star(G_star, _G):\n",
    "                continue\n",
    "            embed_data, map, imap = get_embedded_dataset(data, _G)\n",
    "            # Get M_new from embedded distribution\n",
    "            _M_new, _ = semi_HITON_MB(embed_data, map[target], alpha, is_discrete)\n",
    "            # Remap to M_new\n",
    "            M_new = set([imap[i] for i in _M_new])\n",
    "            print('M_new', M_new)\n",
    "            if check_independence_M_new(data, target, alpha, cit, set(M_new), set(M), _G):\n",
    "                M_queue.append(set(M_new))\n",
    "                G_queue.append(set(_G))\n",
    "            else:\n",
    "                G_star.append(set(_G))\n",
    "            print('M_queue', M_queue)\n",
    "            print('G_queue', G_queue)\n",
    "            print('G_star', G_star)\n",
    "    return M_queue                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "997562fe-4221-48ca-91d3-caf7b49e9018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 3], 13)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_HITON_MB(tie_small_data, 0, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a284b655-26ad-48dc-8ba9-1aaa24591615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M [1, 3]\n",
      "_G (1,)\n",
      "M_new {2, 3}\n",
      "M_queue [{1, 3}]\n",
      "G_queue [[]]\n",
      "G_star [set(), {1}]\n",
      "_G (2,)\n",
      "M_new {1, 3}\n",
      "M_queue [{1, 3}, {1, 3}]\n",
      "G_queue [[], {2}]\n",
      "G_star [set(), {1}]\n",
      "_G (3,)\n",
      "M_new {1}\n",
      "M_queue [{1, 3}, {1, 3}, {1}]\n",
      "G_queue [[], {2}, {3}]\n",
      "G_star [set(), {1}]\n",
      "_G (1, 2)\n",
      "_G (1, 3)\n",
      "_G (2, 3)\n",
      "M_new {1}\n",
      "M_queue [{1, 3}, {1, 3}, {1}, {1}]\n",
      "G_queue [[], {2}, {3}, {2, 3}]\n",
      "G_star [set(), {1}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{1, 3}, {1, 3}, {1}, {1}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tie_star(tie_small_data, 0, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c33cb9f3-d0e2-4853-8750-663ba3af370f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns.values).index('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e7d6319-0313-4f46-93cf-5783b15d723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsq = CIT(tie_small_data, \"gsq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8025d6d6-5df3-4fbc-97fe-17aaad0e9ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgsq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/research/anon/modules/instaCFS/submodules/instaCFS-benchmarks/instaCFS-bench-venv/lib/python3.11/site-packages/causallearn/utils/cit.py:339\u001b[0m, in \u001b[0;36mChisq_or_Gsq.__call__\u001b[0;34m(self, X, Y, condition_set)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, condition_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# Chi-square (or G-square) independence test.\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     Xs, Ys, condition_set, cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_formatted_XYZ_and_cachekey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpvalue_cache: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpvalue_cache[cache_key]\n\u001b[1;32m    341\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m condition_set \u001b[38;5;241m+\u001b[39m Xs \u001b[38;5;241m+\u001b[39m Ys\n",
      "File \u001b[0;32m~/src/research/anon/modules/instaCFS/submodules/instaCFS-benchmarks/instaCFS-bench-venv/lib/python3.11/site-packages/causallearn/utils/cit.py:126\u001b[0m, in \u001b[0;36mCIT_Base.get_formatted_XYZ_and_cachekey\u001b[0;34m(self, X, Y, condition_set)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# usually, X and Y are 1-dimensional index (in constraint-based methods)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m METHODS_SUPPORTING_MULTIDIM_DATA:\n\u001b[0;32m--> 126\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(X), \u001b[38;5;28mint\u001b[39m(Y)) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m) \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(Y), \u001b[38;5;28mint\u001b[39m(X))\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m X \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m condition_set \u001b[38;5;129;01mand\u001b[39;00m Y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m condition_set, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX, Y cannot be in condition_set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X], [Y], condition_set, _stringize([X], [Y], condition_set)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "gsq(0, [1,2], [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330d025-0455-4a99-8063-0f38421f77c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
